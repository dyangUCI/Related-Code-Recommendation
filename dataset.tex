\section{Data Collection}
\label{sec:dataset}
We apply our approach to Stack Overflow (SO) and GitHub. We use code snippets in SO as the pool of user-selected examples and use Java projects in GitHub as our code corpus to search from. We choose these two datasets not only because of their popularity within the programming community, but also because they are part of a larger system of software production. The same users that rely on the hosting and management characteristics of GitHub often have difficulties and need help on the implementation of their computer programs, seek support on SO for their specific problems, or hints of solutions from ones with a degree of similarity, and return to GitHub to apply the knowledge acquired. Previous work have shown that developers often copy and paste code snippets from Stack Overflow to their GitHub projects and make adaptations as needed~\cite{yang2017stack, an2017stack, wu2018developers, zhang2019analyzing}. Our approach will facilicate such opportunistic code reuse process when developers browse code snippets in SO. The use scenario will be: when a user is interested in a code snippet in SO, CodeAid recommends related code fragments from GitHub, showing what other code they may also want to investigate and integrate into their own project. 


\subsection{GitHub}
We downloaded Java projects on GitHub by querying GHTorrent~\cite{gousios2012ghtorrent}. GHTorrent is a scalable, offline mirror of data offered through the GitHub REST API, available to the research community as a service. It provides access to all the metadata of GitHub projects, e.g., the clone url, the number of stars and committers, main programming languages in a project, etc. We use these metadata to screen the projects we would like to keep. Our project selection criteria are:
\begin{itemize}
	\item We only consider GitHub projects that have at least five stars, to avoid toy projects that do not adequately reflect software engineering practices~\cite{kalliamvakou2014promises}.
	\item We only keep non-forked projects, because project forking leads to many identical projects and would unnecessarily skew our recommendation.
	\item Prior work on GitHub cloning finds many identical files among GitHub projects, since developers may copy the whole file into another project without making any changes~\cite{lopes2017dejavu}. To account for this internal duplication in GitHub, we remove duplicated GitHub files using the same file hashing method as in~\cite{lopes2017dejavu}.
\end{itemize} 
As a result, we downloaded 50,826 non-forked Java repositories with at least five stars from GitTorrent. After deduplication, 5,825,727 distinct Java files remain.


\subsection{Stack Overflow}
From the SO dump taken in October 2016, we extract 312,219 answer posts that have {\ttt java} or {\ttt android} tags and also contain code snippets in the {\ttt <code>} markdown. We consider code snippets in answer posts only, since snippets in question posts are rarely used as examples. Since SO snippets are often free-standing statements with low parsable rates, we used a customized pre-processor before tokenization. We add dummy class and method definitions, and semicolons after statements, as needed. For snippets contain multiple methods, we chunk them into individual ones. We keep only parsable SO snippets after pre-processing. Prior work finds that larger SO snippets have more meaningful clones in GitHub~\cite{yang2017stack}. Hence, we choose to study SO examples with no less than 50 tokens after tokenization. We also remove duplicated examples within SO.%\todo{fix the citations}

\subsection{Result for similar code detection}
We run SoucererCC to find all similar pairs between SO and GitHub. We run SCC on a server machine with 116 cores and 256G RAM. It takes 24 hours to complete. As a result, we get 21,207 distinct SO methods that have one or more similar code fragments in GitHub. \todo{distribution of \# of similar counterparts}


\subsection{Result for candidate related methods}
Within the 21,207 groups of SO snippet with GitHub files which contain similar methods to the SO snippet, we extract all co-occurred methods from these GitHub files and treat them as candidate related code fragments. Then for each candidate in each GitHub file, we retrieve its similar counterparts from other files. As a result, we get the co-occurred methods as our candidate related code fragments and for each candidate we also have the frequency of its similar counterparts. Not all groups have candidate methods and not all candidates have similar counterparts in other files, we have 11,110 SO snippets whose candidate related methods do have similar counterparts in other files, that can be taken as the candidate appears more than one files and we take this as a stronger signal for recommendation and only focus on these 11,110 groups from then on. Inside each group, we order the candidates by the number of similar counterparts and returned the ordered list as the final recommendation of related code fragments to the user.
\todo{distribution of number of candidate related methods, distribution of LOC of candidate related methods}


\subsection{Chrom extension for SO}

