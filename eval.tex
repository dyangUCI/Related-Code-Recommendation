\section{Evaluation}
\label{sec:Evaluation}
In this section, we describe the design of the assessment scenarios for \tool\ and report the evaluation results. Specifically, our experiments aim to address the following research questions:
\begin{itemize}
	\item RQ1: Are the code fragments recommended by \tool\ related to the query?
	\item RQ2: What kinds of related code fragments do \tool\ recommend?
	\item RQ3: Can we get the recommended related code fragments from code search engines?
\end{itemize}

\subsection{Manual analysis and categorization}
We randomly select 30 SO snippets with its recommended related code fragments, and manually examine whether the recommended code fragments are related to the SO input or not, and categorize why we call the relationship a relevant one.

We use $Precision@k$ metric to evaluate \tool\  which is defined as follows:
\begin{equation}
Precision@k = \frac{1}{N}\sum_{i=1}^{N}\tfrac{\left | relevant_{i,k} \right |}{k}
\end{equation}
where $\left | relevant_{i,k} \right |$ represents the number of positive related results in the top $k$ results for query $i$, $N$ is the number queries we evaluate, which is $30$. $k$ is the number of top results we examine, here we use $k=1$ and $k=3$.

\tool\ achieves 80\% and 78.9\% for $Precision@1$ and $Precision@3$ respectively. That is to say, for the 30 top 1 recommended results, 24 of them are manual examined as related, for the 90 top 3 recommended resutls, 71 of them are related.

We find the following types of relevance in our sample set.
\begin{itemize}
	\item A complementary method which adds more functionality
	\item A supplmentary method that help with or get help from the query 
	\item A different implementation for the query	
\end{itemize}

\begin{table}
	\begin{center}
		\begin{tabular}{ c|c|c } 
			Category & Top 1 & Top 3 \\\hline
			Complementary method &  12 & 33\\\hline 
			Supplementary method &  11 & 31 \\ \hline
			Different implementation &  1 & 4 \\ \hline
			Not related &6 & 19
		\end{tabular}		
	\end{center}
	\caption{Categorization of related methods}
	\label{tab:categorization}
\end{table}
	
	

\subsubsection{Complementary method} In this category, the query code can function alone, but the recommended related method provides extra functionality to the query code and will further complete the user class. As shown in the Table ~\ref{tab:compl-examples}, \tool\ recommends \texttt{Zip} function when the user implements \texttt{Unzip}. Similarly, \texttt{Decrypt} function for \texttt{Encrypt} and \texttt{onPause} function for \texttt{onCreate}. The two methods do not have any direct function call association between them, but they complete each other with extra functionality and are often implemented together in real-life scenarios. 

\subsubsection{Supplementary method} The recommended related code serves as a helper function to the query, or vice versa. One may make function call to the other. For example the \texttt{Merge} function for \texttt{Sort}. \texttt{Sort} calls \texttt{Merge} as a helper function and cannot achieve functionality without it. Also in our second example Table ~\ref{tab:suppl-examples}, our recommended related code \texttt{loadDrawable} calls \texttt{queueJob} inside its method body. There is another related method being recommended together, which is shown below \ref{lst:part2}. This code is also called by \texttt{loadDrawable}, the related methods give the user a broader picture of the whole class,point to a higher level of functionality the user may want to implement, and also direct the user to the most-frequently used higher level functionality and its auxiliaries.
\begin{lstlisting}[caption={Recommended code \#2}, label={lst:part2}]
public static Drawable getDrawableFromCache(String url) {
	if (DrawableManager.cache.containsKey(url)) {
		return DrawableManager.cache.get(url);
	}
	
	return null;
}	
\end{lstlisting}

\subsection{Different implementation} This category represents those recommended related methods which have similar functionality to the query code. The recommended result provide an alternative, or a more detailed or extended implementation for the functionality. As shown in Table ~\ref{tab:diff-examples}, both of the methods implement sorting values in a \texttt{Map}, the query store the map entries in a \texttt{SortedSet}, while the recommended code uses \texttt{LinkedList}, and shows how to iterate a \texttt{Map}. For the \texttt{encryt} in Table ~\ref{tab:compl-examples}, \tool\ also recommended an alternative implementation with \texttt{String} inputs, as shown in Listing ~\ref{lst:encryt}.


\begin{lstlisting}[caption={different implementation for \texttt{encrypt}}, label={lst:encryt}]
public static String encrypt(final String password, String message) throws GeneralSecurityException {
	try {
		final SecretKeySpec key = generateKey(password);
		log("message", message);
		byte[] cipherText = encrypt(key, ivBytes, message.getBytes(CHARSET));
		//NO_WRAP is important as was getting \n at the end
		String encoded = String.valueOf(
			Base64.encodeToString(cipherText, Base64.NO_PADDING ));
		log("Base64.NO_WRAP", encoded);
		return encoded;
	} catch (UnsupportedEncodingException e) {
		if (DEBUG_LOG_ENABLED)
			Log.e(TAG, "UnsupportedEncodingException ", e);
		throw new GeneralSecurityException(e);
	}
}
\end{lstlisting}

\input{example-table}

\subsection{Comparison with code search engines}
In this experiment we compare the recommendation results of \tool\ with those from code search engines. We focus on Google search and Stack Overflow search since these are popular destinations when people look for programming assistance. We also compare to \texttt{FaCoy}, a code-to-code-search engine which proved to have state-of-art precision. In the experiments above, we get 24 valid related code fragments as top 1 result recommended by \tool. We randomly select 6 snippets from them. For \texttt{FaCoy}, we use the snippets directly as search queries since it supports code-to-code search. For Google and SO search engine, we trace back to the SO post where the SO snippet originated, and summarize the context around the snippet as the search query. We show that whether the search engines can also retrieve top 1 related code fragments as \tool in their top 10 search results. 

Table \ref{tab:so-questions} lists the titles of SO posts used as search queries in our experiment.

\begin{table}
	\begin{center}
		\begin{tabular}{ c|c } 
			Query & Question title \\\hline 
			Q1 &  java unzip files from a specific folder\\\hline 
			Q2 &  2 \\ \hline
			Q3 &  3 \\ \hline
			Q4 &  4 \\ \hline
			Q5 &  5 \\ \hline
			Q6 &  6 \\ \hline
		\end{tabular}		
	\end{center}
	\caption{Queries for Google search and SO search}
	\label{tab:so-questions}
\end{table}

One example search query for \textit{FaCoy} is shown in List ~\ref{lst:facoy-query}.
\begin{lstlisting}[label={lst:facoy-query}]
	sample
\end{lstlisting}

\begin{table}
	\begin{center}
		\begin{tabular}{ c|c|c|c } 
			Query & Google search & SO search & FaCoy \\ 
			Q1 &  1  & &\\\hline 
			Q2 &  2 & &\\ \hline
			Q3 &  3 & &\\ \hline
			Q4 &  4 & &\\ \hline
			Q5 &  5 & & \\ \hline
			Q6 &  6 & &\\ \hline
		\end{tabular}		
	\end{center}
	\caption{Search results}
	\label{tab:so-questions}
\end{table}
